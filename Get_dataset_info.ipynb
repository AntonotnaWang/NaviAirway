{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c0131b",
   "metadata": {},
   "source": [
    "### Get dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import edt\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d11430",
   "metadata": {},
   "source": [
    "### Get pre-cropped LIDC-IDRI dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1732f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precrop_dataset_for_train_path = \"/data/Airway/Precrop_dataset_for_LIDC-IDRI\"\n",
    "Precrop_dataset_for_train_raw_path = Precrop_dataset_for_train_path+\"/image\"\n",
    "Precrop_dataset_for_train_label_path = Precrop_dataset_for_train_path+\"/label\"\n",
    "\n",
    "raw_case_name_list = os.listdir(Precrop_dataset_for_train_raw_path)\n",
    "label_case_name_list = os.listdir(Precrop_dataset_for_train_label_path)\n",
    "\n",
    "assert raw_case_name_list == label_case_name_list\n",
    "\n",
    "data_dict = dict()\n",
    "\n",
    "for idx, name in enumerate(raw_case_name_list):\n",
    "    print(\"process \"+str(name)+\" | \"+str(idx/len(raw_case_name_list)), end=\"\\r\")\n",
    "    data_dict[name.split(\".\")[0]]={}\n",
    "    data_dict[name.split(\".\")[0]][\"image\"]=Precrop_dataset_for_train_raw_path+\"/\"+name\n",
    "    data_dict[name.split(\".\")[0]][\"label\"]=Precrop_dataset_for_train_label_path+\"/\"+name\n",
    "    label_temp = np.load(Precrop_dataset_for_train_label_path+\"/\"+name)\n",
    "    data_dict[name.split(\".\")[0]][\"airway_pixel_num\"]=np.sum(label_temp)\n",
    "    \n",
    "    label_temp=np.array(label_temp, dtype=np.uint32, order='F')\n",
    "    label_temp_edt=edt.edt(\n",
    "        label_temp,\n",
    "        black_border=True, order='F',\n",
    "        parallel=1)\n",
    "    \n",
    "    data_dict[name.split(\".\")[0]][\"airway_pixel_num_boundary\"] = len(np.where(label_temp_edt==1)[0])\n",
    "    data_dict[name.split(\".\")[0]][\"airway_pixel_num_inner\"] = len(np.where(label_temp_edt>1)[0])\n",
    "\n",
    "save_obj(data_dict, \"dataset_info_LIDC_IDRI_crops_128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4298c",
   "metadata": {},
   "source": [
    "### Get pre-cropped EXACT09 dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6781c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precrop_dataset_for_train_path = \"/data/Airway/Precrop_dataset_for_EXACT09\"\n",
    "Precrop_dataset_for_train_raw_path = Precrop_dataset_for_train_path+\"/image\"\n",
    "Precrop_dataset_for_train_label_path = Precrop_dataset_for_train_path+\"/label\"\n",
    "\n",
    "raw_case_name_list = os.listdir(Precrop_dataset_for_train_raw_path)\n",
    "label_case_name_list = os.listdir(Precrop_dataset_for_train_label_path)\n",
    "\n",
    "assert raw_case_name_list == label_case_name_list\n",
    "\n",
    "data_dict = dict()\n",
    "\n",
    "for idx, name in enumerate(raw_case_name_list):\n",
    "    print(\"process \"+str(name)+\" | \"+str(idx/len(raw_case_name_list)), end=\"\\r\")\n",
    "    data_dict[name.split(\".\")[0]]={}\n",
    "    data_dict[name.split(\".\")[0]][\"image\"]=Precrop_dataset_for_train_raw_path+\"/\"+name\n",
    "    data_dict[name.split(\".\")[0]][\"label\"]=Precrop_dataset_for_train_label_path+\"/\"+name\n",
    "    label_temp = np.load(Precrop_dataset_for_train_label_path+\"/\"+name)\n",
    "    data_dict[name.split(\".\")[0]][\"airway_pixel_num\"]=np.sum(label_temp)\n",
    "    \n",
    "    label_temp=np.array(label_temp, dtype=np.uint32, order='F')\n",
    "    label_temp_edt=edt.edt(\n",
    "        label_temp,\n",
    "        black_border=True, order='F',\n",
    "        parallel=1)\n",
    "    \n",
    "    data_dict[name.split(\".\")[0]][\"airway_pixel_num_boundary\"] = len(np.where(label_temp_edt==1)[0])\n",
    "    data_dict[name.split(\".\")[0]][\"airway_pixel_num_inner\"] = len(np.where(label_temp_edt>1)[0])\n",
    "\n",
    "save_obj(data_dict, \"dataset_info_EXACT09_crops_128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f95d9f",
   "metadata": {},
   "source": [
    "### Get the case names of LIDC-IDRI and EXACT09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXACT_img_niigz_path = \"/data/Airway/EXACT09_3D/train\"\n",
    "EXACT_label_niigz_path = \"/data/Airway/EXACT09_3D/train_label\"\n",
    "LIDC_IDRI_img_niigz_path = \"/data/Airway/LIDC-IDRI_3D/annotated_data/image\"\n",
    "LIDC_IDRI_label_niigz_path = \"/data/Airway/LIDC-IDRI_3D/annotated_data/label\"\n",
    "\n",
    "EXACT_names = os.listdir(EXACT_img_niigz_path)\n",
    "EXACT_names.sort()\n",
    "EXACT_label_names = os.listdir(EXACT_label_niigz_path)\n",
    "EXACT_label_names.sort()\n",
    "print(EXACT_names, EXACT_label_names)\n",
    "\n",
    "LIDC_names = os.listdir(LIDC_IDRI_img_niigz_path)\n",
    "LIDC_names.sort()\n",
    "LIDC_IDRI_label_names = os.listdir(LIDC_IDRI_label_niigz_path)\n",
    "LIDC_IDRI_label_names.sort()\n",
    "print(LIDC_names, LIDC_IDRI_label_names)\n",
    "\n",
    "EXACT09_names = []\n",
    "for EXACT09_name in EXACT_names:\n",
    "    EXACT09_names.append(\"EXACT09_\"+EXACT09_name.split(\".\")[0])\n",
    "EXACT09_names = np.array(EXACT09_names)\n",
    "EXACT09_names = np.unique(EXACT09_names)\n",
    "\n",
    "LIDC_IDRI_names = []\n",
    "for LIDC_IDRI_name in LIDC_names:\n",
    "    LIDC_IDRI_names.append(\"LIDC_IDRI_\"+LIDC_IDRI_name.split(\".\")[0])\n",
    "LIDC_IDRI_names = np.array(LIDC_IDRI_names)\n",
    "LIDC_IDRI_names = np.unique(LIDC_IDRI_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b369c",
   "metadata": {},
   "source": [
    "### Split train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.concatenate((EXACT09_names, LIDC_IDRI_names))\n",
    "\n",
    "# you can split train/test by yourself\n",
    "# just show an example\n",
    "\n",
    "test_names = ['LIDC_IDRI_0698', 'LIDC_IDRI_0710', 'LIDC_IDRI_0810',\n",
    "        'LIDC_IDRI_0376', 'EXACT09_CASE13', 'LIDC_IDRI_1004',\n",
    "        'EXACT09_CASE08', 'EXACT09_CASE01', 'EXACT09_CASE05',\n",
    "        'LIDC_IDRI_0744']\n",
    "print(\"test name: \"+str(test_names))\n",
    "train_names = []\n",
    "for name in names:\n",
    "    if name not in test_names:\n",
    "        train_names.append(name)\n",
    "train_names=np.array(train_names)\n",
    "print(\"train names: \"+str(train_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d4806",
   "metadata": {},
   "source": [
    "### Get dataset dict for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c57272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_EXACT09_128=load_obj(\"dataset_info/dataset_info_EXACT09_crops_128\")\n",
    "data_dict_LIDC_IDRI_128=load_obj(\"dataset_info/dataset_info_LIDC_IDRI_crops_128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b340fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set_dict_EXACT09_LIDC_IDRI_128={}\n",
    "train_test_set_dict_EXACT09_LIDC_IDRI_128[\"train\"]={}\n",
    "train_test_set_dict_EXACT09_LIDC_IDRI_128[\"test\"]={}\n",
    "\n",
    "for case in data_dict_EXACT09_128.keys():\n",
    "    if (case.split(\"_\")[0]+\"_\"+case.split(\"_\")[1]) in train_names:\n",
    "        train_test_set_dict_EXACT09_LIDC_IDRI_128[\"train\"][case] = data_dict_EXACT09_128[case]\n",
    "    elif (case.split(\"_\")[0]+\"_\"+case.split(\"_\")[1]) in test_names:\n",
    "        train_test_set_dict_EXACT09_LIDC_IDRI_128[\"test\"][case] = data_dict_EXACT09_128[case]\n",
    "\n",
    "for case in data_dict_LIDC_IDRI_128.keys():\n",
    "    if (case.split(\"_\")[0]+\"_\"+case.split(\"_\")[1]+\"_\"+case.split(\"_\")[2]) in train_names:\n",
    "        train_test_set_dict_EXACT09_LIDC_IDRI_128[\"train\"][case] = data_dict_LIDC_IDRI_128[case]\n",
    "    elif (case.split(\"_\")[0]+\"_\"+case.split(\"_\")[1]+\"_\"+case.split(\"_\")[2]) in test_names:\n",
    "        train_test_set_dict_EXACT09_LIDC_IDRI_128[\"test\"][case] = data_dict_LIDC_IDRI_128[case]\n",
    "\n",
    "train_test_set_dict_EXACT09_LIDC_IDRI_128[\"train_names\"]=train_names\n",
    "train_test_set_dict_EXACT09_LIDC_IDRI_128[\"test_names\"]=test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb425a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set_dict_EXACT09_LIDC_IDRI_128[\"train\"]\n",
    "# it has all info of images crops for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904a6aa",
   "metadata": {},
   "source": [
    "### Get dataset_info for iterative training strategy. First, train with higher frequency on airways of high generations. Next, train with higher frequency on airways of low generations. And repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_org=train_test_set_dict_EXACT09_LIDC_IDRI_128['train']\n",
    "\n",
    "import copy\n",
    "data_dict_extended = copy.deepcopy(data_dict_org)\n",
    "\n",
    "is_more_big = True # higher freq on airways of low gen (thicker airways)\n",
    "copy_times_I = 10\n",
    "\n",
    "for idx, case in enumerate(data_dict_org.keys()):\n",
    "    if data_dict_org[case][\"airway_pixel_num\"]>0:\n",
    "        if is_more_big:\n",
    "            copy_times_II = np.ceil(data_dict_org[case][\"airway_pixel_num_inner\"]/data_dict_org[case][\"airway_pixel_num_boundary\"])\n",
    "        else:\n",
    "            if data_dict_org[case][\"airway_pixel_num_inner\"]==0:\n",
    "                copy_times_II = np.ceil(data_dict_org[case][\"airway_pixel_num_boundary\"])\n",
    "            else:\n",
    "                copy_times_II = np.ceil(data_dict_org[case][\"airway_pixel_num_boundary\"]/data_dict_org[case][\"airway_pixel_num_inner\"])\n",
    "\n",
    "        for i in range(int(copy_times_I*copy_times_II)):\n",
    "            data_dict_extended[case+\"_copy_\"+str(i+1)]=data_dict_org[case]\n",
    "if is_more_big:\n",
    "    save_obj(data_dict_extended, \"dataset_info/train_dataset_info_EXACT09_LIDC_IDRI_crops_128_extended_\"+\"more_low_gen_\"+str(copy_times_I))\n",
    "else:\n",
    "    save_obj(data_dict_extended, \"dataset_info/train_dataset_info_EXACT09_LIDC_IDRI_crops_128_extended_\"+\"more_high_gen_\"+str(copy_times_I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55b1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
